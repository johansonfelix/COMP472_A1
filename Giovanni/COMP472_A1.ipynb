{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from codecs import open\n",
    "from __future__ import division\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_documents(doc_file):\n",
    "    docs = []\n",
    "    labels = []\n",
    "    with open(doc_file, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            words = line.strip().split()\n",
    "            docs.append(\" \".join(words[3:]))\n",
    "            labels.append(words[1])\n",
    "    return docs, labels\n",
    "\n",
    "all_docs, all_labels = read_documents('all_sentiment_shuffled.txt')\n",
    "\n",
    "split_point = int(0.80*len(all_docs))\n",
    "train_docs = all_docs[:split_point]\n",
    "train_labels = all_labels[:split_point]\n",
    "eval_docs = all_docs[split_point:]\n",
    "eval_labels = all_labels[split_point:]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "train_docs_vector = vectorizer.fit_transform(train_docs)\n",
    "eval_docs_vector = vectorizer.transform(eval_docs)\n",
    "\n",
    "data = {'pos':all_labels.count(\"pos\"), 'neg':all_labels.count(\"neg\")} \n",
    "ratings = list(data.keys()) \n",
    "counts = list(data.values()) \n",
    "\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "plt.bar(ratings, counts)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "clf = MultinomialNB().fit(train_docs_vector, train_labels)\n",
    "prediction_naive = clf.predict(eval_docs_vector)\n",
    "\n",
    "naive_cm = confusion_matrix(eval_labels, prediction_naive)\n",
    "naive_ps = precision_score(eval_labels, prediction_naive, average='weighted')\n",
    "naive_rs = recall_score(eval_labels, prediction_naive, average='weighted')\n",
    "naive_f1 = f1_score(eval_labels, prediction_naive, average='weighted')\n",
    "naive_accuracy = accuracy_score(eval_labels, prediction_naive, normalize=True)\n",
    "\n",
    "f = open(\"Naive Bayes - all_sentiment_shuffled.txt\", \"w\")\n",
    "sp_inc = split_point \n",
    "for x in prediction_naive:\n",
    "    f.write(f\"{sp_inc}, {x}\\n\")\n",
    "    sp_inc += 1\n",
    "    \n",
    "f.write(\"\\nConfusion Matrix for Naive Bayes: \" + str(naive_cm))\n",
    "f.write(\"\\nPrecision Score for Naive Bayes: \" + str(naive_ps))\n",
    "f.write(\"\\nRecall Score for Naive Bayes: \" + str(naive_rs))\n",
    "f.write(\"\\nf1-measure for Naive Bayes: \" + str(naive_f1))\n",
    "f.write(\"\\nAccuracy for Naive Bayes: \" + str(naive_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "clf.fit(train_docs_vector, train_labels)\n",
    "prediction_base = clf.predict(eval_docs_vector)\n",
    "\n",
    "naive_cm = confusion_matrix(eval_labels, prediction_base)\n",
    "naive_ps = precision_score(eval_labels, prediction_base, average='weighted')\n",
    "naive_rs = recall_score(eval_labels, prediction_base, average='weighted')\n",
    "naive_f1 = f1_score(eval_labels, prediction_base, average='weighted')\n",
    "naive_accuracy = accuracy_score(eval_labels, prediction_base, normalize=True)\n",
    "\n",
    "f = open(\"Base-DT - all_sentiment_shuffled.txt\", \"w\")\n",
    "sp_inc = split_point \n",
    "for x in prediction_base:\n",
    "    f.write(f\"{sp_inc}, {x}\\n\")\n",
    "    sp_inc += 1\n",
    "    \n",
    "f.write(\"\\nConfusion Matrix for Naive Bayes: \" + str(naive_cm))\n",
    "f.write(\"\\nPrecision Score for Naive Bayes: \" + str(naive_ps))\n",
    "f.write(\"\\nRecall Score for Naive Bayes: \" + str(naive_rs))\n",
    "f.write(\"\\nf1-measure for Naive Bayes: \" + str(naive_f1))\n",
    "f.write(\"\\nAccuracy for Naive Bayes: \" + str(naive_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion = 'gini', splitter = 'best')\n",
    "clf.fit(train_docs_vector, train_labels)\n",
    "prediction_best = clf.predict(eval_docs_vector)\n",
    "\n",
    "naive_cm = confusion_matrix(eval_labels, prediction_best)\n",
    "naive_ps = precision_score(eval_labels, prediction_best, average='weighted')\n",
    "naive_rs = recall_score(eval_labels, prediction_best, average='weighted')\n",
    "naive_f1 = f1_score(eval_labels, prediction_best, average='weighted')\n",
    "naive_accuracy = accuracy_score(eval_labels, prediction_best, normalize=True)\n",
    "\n",
    "f = open(\"Best-DT - all_sentiment_shuffled.txt\", \"w\")\n",
    "sp_inc = split_point \n",
    "for x in prediction_best:\n",
    "    f.write(f\"{sp_inc}, {x}\\n\")\n",
    "    sp_inc += 1\n",
    "\n",
    "f.write(\"\\nConfusion Matrix for Naive Bayes: \" + str(naive_cm))\n",
    "f.write(\"\\nPrecision Score for Naive Bayes: \" + str(naive_ps))\n",
    "f.write(\"\\nRecall Score for Naive Bayes: \" + str(naive_rs))\n",
    "f.write(\"\\nf1-measure for Naive Bayes: \" + str(naive_f1))\n",
    "f.write(\"\\nAccuracy for Naive Bayes: \" + str(naive_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9502, 9505, 9515, 9517, 9522, 9530, 9540, 9541, 9543, 9546, 9548, 9556, 9558, 9569, 9570, 9572, 9573, 9581, 9584, 9585, 9589, 9592, 9594, 9623, 9627, 9628, 9629, 9633, 9641, 9644, 9646, 9652, 9655, 9657, 9660, 9665, 9681, 9689, 9692, 9694, 9699, 9700, 9703, 9704, 9705, 9711, 9757, 9762, 9767, 9772, 9803, 9806, 9815, 9819, 9831, 9835, 9836, 9839, 9840, 9848, 9849, 9853, 9856, 9858, 9873, 9876, 9882, 9886, 9888, 9890, 9893, 9897, 9904, 9909, 9920, 9943, 9945, 9946, 9947, 9951, 9954, 9964, 9967, 9978, 9979, 9999, 10001, 10003, 10004, 10011, 10014, 10021, 10026, 10028, 10035, 10049, 10052, 10055, 10057, 10060, 10063, 10072, 10074, 10076, 10077, 10080, 10083, 10090, 10092, 10099, 10101, 10103, 10107, 10110, 10113, 10125, 10127, 10131, 10141, 10148, 10161, 10175, 10176, 10177, 10180, 10185, 10189, 10195, 10197, 10204, 10207, 10208, 10209, 10261, 10263, 10264, 10265, 10266, 10271, 10273, 10276, 10277, 10303, 10313, 10319, 10330, 10332, 10335, 10337, 10344, 10354, 10355, 10363, 10369, 10372, 10377, 10378, 10380, 10385, 10386, 10391, 10392, 10394, 10403, 10405, 10406, 10407, 10408, 10410, 10433, 10435, 10443, 10444, 10458, 10469, 10470, 10480, 10487, 10491, 10492, 10500, 10503, 10505, 10506, 10515, 10535, 10546, 10550, 10551, 10559, 10564, 10580, 10587, 10594, 10609, 10612, 10614, 10622, 10623, 10634, 10643, 10645, 10659, 10668, 10672, 10678, 10680, 10682, 10690, 10695, 10698, 10700, 10710, 10722, 10723, 10750, 10753, 10756, 10757, 10759, 10760, 10763, 10766, 10768, 10769, 10787, 10788, 10789, 10815, 10818, 10824, 10825, 10834, 10840, 10843, 10863, 10864, 10869, 10874, 10877, 10886, 10890, 10893, 10900, 10904, 10909, 10910, 10911, 10914, 10926, 10927, 10928, 10943, 10944, 10950, 10961, 10965, 10973, 10990, 11009, 11010, 11011, 11014, 11020, 11022, 11026, 11038, 11042, 11043, 11048, 11059, 11062, 11063, 11067, 11069, 11078, 11080, 11082, 11085, 11089, 11092, 11098, 11104, 11115, 11117, 11129, 11138, 11139, 11142, 11144, 11145, 11147, 11150, 11152, 11157, 11158, 11164, 11181, 11183, 11185, 11194, 11195, 11213, 11214, 11215, 11216, 11228, 11231, 11233, 11234, 11245, 11248, 11250, 11255, 11258, 11271, 11272, 11287, 11301, 11311, 11312, 11317, 11322, 11326, 11327, 11337, 11344, 11355, 11361, 11365, 11367, 11376, 11378, 11387, 11395, 11402, 11406, 11413, 11420, 11434, 11445, 11446, 11449, 11465, 11470, 11471, 11477, 11479, 11485, 11494, 11510, 11511, 11514, 11515, 11516, 11520, 11523, 11526, 11533, 11538, 11548, 11553, 11561, 11565, 11577, 11581, 11589, 11592, 11593, 11595, 11600, 11601, 11603, 11610, 11611, 11615, 11616, 11619, 11620, 11621, 11624, 11629, 11630, 11632, 11635, 11637, 11644, 11653, 11663, 11665, 11666, 11680, 11683, 11690, 11697, 11698, 11700, 11712, 11713, 11720, 11723, 11727, 11734, 11738, 11741, 11755, 11757, 11759, 11766, 11773, 11777, 11778, 11785, 11793, 11796, 11801, 11803, 11811, 11813, 11825, 11826, 11829, 11843, 11851, 11853, 11862, 11868]\n"
     ]
    }
   ],
   "source": [
    "error_list = list()\n",
    "\n",
    "for i in range(len(eval_labels)):\n",
    "    if prediction_naive[i] != eval_labels[i]:\n",
    "        error_list.append(i + split_point)\n",
    "\n",
    "# you may select a few short documents where the probabilities were particularly high in the wrong\n",
    "# direction.\n",
    "\n",
    "print(error_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
