{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codecs import open #For func _read_documents\n",
    "from __future__ import division #For func _read_documents\n",
    "from collections import Counter #For frequency function\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to read file\n",
    "def read_documents(doc_file):\n",
    "    labels = []\n",
    "    docs = []\n",
    "    all_docs_freq = []\n",
    "    \n",
    "    with open(doc_file, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            \n",
    "            #Noise reduction - Removing punctuation \n",
    "            line = line.replace(\",\",\" \")\n",
    "            line = line.replace(\".\",\" \")\n",
    "            line = line.replace('\\\"',\" \")\n",
    "            line = line.replace('(',\" \")\n",
    "            line = line.replace(')',\" \")\n",
    "            line = line.replace('!',\" \")\n",
    "            \n",
    "            #Storing data\n",
    "            words = line.strip().split() \n",
    "            labels.append(words[1])\n",
    "            docs.append(' '.join(words[4:]))\n",
    "            all_docs_freq.append(words[4:])        \n",
    "            \n",
    "    return labels,docs,all_docs_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 0\n",
    "\n",
    "#Reading in data + removing document identifier and topic label\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from pandas import DataFrame\n",
    "\n",
    "all_labels, all_docs,all_docs_freq = read_documents('all_sentiment_shuffled.txt')\n",
    "\n",
    "#Counting the frequency of words throughout all reviews\n",
    "freq = Counter()\n",
    "for i in range(len(all_docs_freq)):\n",
    "    for w in all_docs_freq[i]: \n",
    "        freq[w] += 1\n",
    "\n",
    "#Changing freq from list of key-value pairs to list of keys. This way it can be used as a vocabulary for CountVectorizer\n",
    "num_of_features = 8000 #Change this value to alter the number of features for the models\n",
    "common = freq.most_common(num_of_features) \n",
    "features = []\n",
    "for i in range(len(common)):\n",
    "    features.append(common[i][0])\n",
    "\n",
    "        \n",
    "#Splitting data into training and testing set\n",
    "split_point = int(0.80*len(all_docs)) \n",
    "train_docs = all_docs[:split_point] \n",
    "target_train = all_labels[:split_point] \n",
    "eval_docs = all_docs[split_point:] \n",
    "target_test = all_labels[split_point:]\n",
    "\n",
    "\n",
    "#Formatting data using CountVectorizer \n",
    "vect = CountVectorizer(vocabulary = features)\n",
    "data_train = vect.transform(train_docs)\n",
    "data_test = vect.transform(eval_docs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 842.4x595.44 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Task 1\n",
    "\n",
    "#Forming DataFrame using labels -- allows for easy plotting \n",
    "labelsDF = DataFrame(all_labels, columns = [\"labels\"])\n",
    "\n",
    "#Plotting data\n",
    "sns.set(style=\"whitegrid\",color_codes = True)\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.countplot(x = 'labels',data=labelsDF)\n",
    "sns.despine(offset=10, trim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive-Bayes (smoothing = 1) accuracy :  0.8697933060539292\n",
      "Naive-Bayes (smoothing = 1) weighted recall :  0.8697933060539292\n",
      "Naive-Bayes (smoothing = 1) weighted precision :  0.8703863913034763\n",
      "Naive-Bayes (smoothing = 1) weighted f1-measure :  0.8697897541712533\n",
      "\n",
      "Naive-Bayes (smoothing = 0.25) accuracy :  0.8716818801804638\n",
      "Naive-Bayes (smoothing = 0.25) weighted recall :  0.8716818801804638\n",
      "Naive-Bayes (smoothing = 0.25) weighted precision :  0.872180393954905\n",
      "Naive-Bayes (smoothing = 0.25) weighted f1-measure :  0.8716823350291443\n",
      "\n",
      "Naive-Bayes (smoothing = 0.1) accuracy :  0.8718917217500787\n",
      "Naive-Bayes (smoothing = 0.1) weighted recall :  0.8718917217500787\n",
      "Naive-Bayes (smoothing = 0.1) weighted precision :  0.8723789439812635\n",
      "Naive-Bayes (smoothing = 0.1) weighted f1-measure :  0.8718926186778012\n",
      "\n",
      "Naive-Bayes (smoothing = 0.05) accuracy :  0.8719966425348862\n",
      "Naive-Bayes (smoothing = 0.05) weighted recall :  0.8719966425348862\n",
      "Naive-Bayes (smoothing = 0.05) weighted precision :  0.8724782650223076\n",
      "Naive-Bayes (smoothing = 0.05) weighted f1-measure :  0.8719977557308751\n",
      "\n",
      "Naive-Bayes (smoothing = 0.025) accuracy :  0.8723114048893086\n",
      "Naive-Bayes (smoothing = 0.025) weighted recall :  0.8723114048893086\n",
      "Naive-Bayes (smoothing = 0.025) weighted precision :  0.8727988549019033\n",
      "Naive-Bayes (smoothing = 0.025) weighted f1-measure :  0.8723122988786928\n"
     ]
    }
   ],
   "source": [
    "#Task 2: Naive Bayes: Training\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score\n",
    "\n",
    "#Creating object of MultinomialNB and training the data set\n",
    "\n",
    "#Model Building\n",
    "mnb = MultinomialNB()\n",
    "pred = mnb.fit(data_train, target_train).predict(data_train)\n",
    "print(\"Naive-Bayes (smoothing = 1) accuracy : \",accuracy_score(target_train, pred, normalize = True))\n",
    "print(\"Naive-Bayes (smoothing = 1) weighted recall : \",recall_score(target_train, pred, average = 'weighted'))\n",
    "print(\"Naive-Bayes (smoothing = 1) weighted precision : \",precision_score(target_train, pred, average = 'weighted'))\n",
    "print(\"Naive-Bayes (smoothing = 1) weighted f1-measure : \",f1_score(target_train, pred, average = 'weighted'))\n",
    "\n",
    "\n",
    "#Adjusting hyper-parameters: smoothing\n",
    "mnb = MultinomialNB(alpha = 0.25)\n",
    "pred = mnb.fit(data_train, target_train).predict(data_train)\n",
    "print(\"\\nNaive-Bayes (smoothing = 0.25) accuracy : \",accuracy_score(target_train, pred, normalize = True))\n",
    "print(\"Naive-Bayes (smoothing = 0.25) weighted recall : \",recall_score(target_train, pred, average = 'weighted'))\n",
    "print(\"Naive-Bayes (smoothing = 0.25) weighted precision : \",precision_score(target_train, pred, average = 'weighted'))\n",
    "print(\"Naive-Bayes (smoothing = 0.25) weighted f1-measure : \",f1_score(target_train, pred, average = 'weighted'))\n",
    "\n",
    "\n",
    "#Adjusting hyper-parameters: smoothing\n",
    "mnb = MultinomialNB(alpha = 0.1)\n",
    "pred = mnb.fit(data_train, target_train).predict(data_train)\n",
    "print(\"\\nNaive-Bayes (smoothing = 0.1) accuracy : \",accuracy_score(target_train, pred, normalize = True))\n",
    "print(\"Naive-Bayes (smoothing = 0.1) weighted recall : \",recall_score(target_train, pred, average = 'weighted'))\n",
    "print(\"Naive-Bayes (smoothing = 0.1) weighted precision : \",precision_score(target_train, pred, average = 'weighted'))\n",
    "print(\"Naive-Bayes (smoothing = 0.1) weighted f1-measure : \",f1_score(target_train, pred, average = 'weighted'))\n",
    "\n",
    "#Adjusting hyper-parameters: smoothing\n",
    "mnb = MultinomialNB(alpha = 0.05)\n",
    "pred = mnb.fit(data_train, target_train).predict(data_train)\n",
    "print(\"\\nNaive-Bayes (smoothing = 0.05) accuracy : \",accuracy_score(target_train, pred, normalize = True))\n",
    "print(\"Naive-Bayes (smoothing = 0.05) weighted recall : \",recall_score(target_train, pred, average = 'weighted'))\n",
    "print(\"Naive-Bayes (smoothing = 0.05) weighted precision : \",precision_score(target_train, pred, average = 'weighted'))\n",
    "print(\"Naive-Bayes (smoothing = 0.05) weighted f1-measure : \",f1_score(target_train, pred, average = 'weighted'))\n",
    "\n",
    "#Adjusting hyper-parameters: smoothing\n",
    "mnb = MultinomialNB(alpha = 0.025)\n",
    "pred = mnb.fit(data_train, target_train).predict(data_train)\n",
    "print(\"\\nNaive-Bayes (smoothing = 0.025) accuracy : \",accuracy_score(target_train, pred, normalize = True))\n",
    "print(\"Naive-Bayes (smoothing = 0.025) weighted recall : \",recall_score(target_train, pred, average = 'weighted'))\n",
    "print(\"Naive-Bayes (smoothing = 0.025) weighted precision : \",precision_score(target_train, pred, average = 'weighted'))\n",
    "print(\"Naive-Bayes (smoothing = 0.025) weighted f1-measure : \",f1_score(target_train, pred, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive-Bayes (smoothing = 0.05) accuracy :  0.8191355434326479\n",
      "Naive-Bayes (smoothing = 0.05) weighted recall :  0.8191355434326479\n",
      "Naive-Bayes (smoothing = 0.05) weighted precision :  0.8192373435226762\n",
      "Naive-Bayes (smoothing = 0.05) weighted f1-measure :  0.8191620614979724\n"
     ]
    }
   ],
   "source": [
    "#Task 2: Naive Bayes: Testing\n",
    "#Model Testing - Chosen smoothing value = 0.05\n",
    "#Chose 0.05 rather than 0.025 to prevent overfitting \n",
    "mnb = MultinomialNB(alpha = 0.05)\n",
    "pred = mnb.fit(data_train, target_train).predict(data_test)\n",
    "print(\"\\nNaive-Bayes (smoothing = 0.05) accuracy : \",accuracy_score(target_test, pred, normalize = True))\n",
    "print(\"Naive-Bayes (smoothing = 0.05) weighted recall : \",recall_score(target_test, pred, average = 'weighted'))\n",
    "print(\"Naive-Bayes (smoothing = 0.05) weighted precision : \",precision_score(target_test, pred, average = 'weighted'))\n",
    "print(\"Naive-Bayes (smoothing = 0.05) weighted f1-measure : \",f1_score(target_test, pred, average = 'weighted'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Base-DT accuracy :  0.9998950792151925\n",
      "Base-DT weighted recall :  0.9998950792151925\n",
      "Base-DT weighted precision :  0.9998951016102374\n",
      "Base-DT weighted f1-measure :  0.9998950794023578\n"
     ]
    }
   ],
   "source": [
    "#Task 2: Base-DT: Training\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "clf = DecisionTreeClassifier(criterion = 'entropy')\n",
    "pred = clf.fit(data_train,target_train).predict(data_train)\n",
    "print(\"\\nBase-DT accuracy : \",accuracy_score(target_train, pred, normalize = True))\n",
    "print(\"Base-DT weighted recall : \",recall_score(target_train, pred, average = 'weighted'))\n",
    "print(\"Base-DT weighted precision : \",precision_score(target_train, pred, average = 'weighted'))\n",
    "print(\"Base-DT weighted f1-measure : \",f1_score(target_train, pred, average = 'weighted'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Base-DT accuracy :  0.6852706672261855\n",
      "Base-DT weighted recall :  0.6852706672261855\n",
      "Base-DT weighted precision :  0.6865627421261534\n",
      "Base-DT weighted f1-measure :  0.6852906195529649\n"
     ]
    }
   ],
   "source": [
    "#Task 2: Base-DT: Testing\n",
    "pred = clf.fit(data_train,target_train).predict(data_test)\n",
    "print(\"\\nBase-DT accuracy : \",accuracy_score(target_test, pred, normalize = True))\n",
    "print(\"Base-DT weighted recall : \",recall_score(target_test, pred, average = 'weighted'))\n",
    "print(\"Base-DT weighted precision : \",precision_score(target_test, pred, average = 'weighted'))\n",
    "print(\"Base-DT weighted f1-measure : \",f1_score(target_test, pred, average = 'weighted'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best-DT accuracy :  0.7184221569450273\n",
      "Best-DT weighted recall :  0.7184221569450273\n",
      "Best-DT weighted precision :  0.7186792192777415\n",
      "Best-DT weighted f1-measure :  0.7184837731655974\n"
     ]
    }
   ],
   "source": [
    "#Task 2: Best-DT: Training and testing\n",
    "#Used class_weight = balanced and splitter = random to attempt to improve performance\n",
    "#Adjust max_depth\n",
    "depth = num_of_features-int(0.9*(num_of_features))\n",
    "clf = DecisionTreeClassifier(criterion = 'entropy', class_weight = 'balanced', splitter = 'random', max_depth = depth)\n",
    "pred = clf.fit(data_train,target_train).predict(data_test)\n",
    "\n",
    "print(\"Best-DT accuracy : \",accuracy_score(target_test, pred, normalize = True))\n",
    "print(\"Best-DT weighted recall : \",recall_score(target_test, pred, average = 'weighted'))\n",
    "print(\"Best-DT weighted precision : \",precision_score(target_test, pred, average = 'weighted'))\n",
    "print(\"Best-DT weighted f1-measure : \",f1_score(target_test, pred, average = 'weighted'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 3: Writing to file - Helper functions\n",
    "\n",
    "#Function to print confusion_matrix to file\n",
    "def mat_to_file(cm):\n",
    "    f.write('Confusion Matrix: \\n\\n')\n",
    "    f.write('               Model Prediction\\n')\n",
    "    f.write('                   pos neg\\n')\n",
    "    f.write('Actual label: pos [' + str(cm[0][0]) + ' ' + str(cm[0][1]) + ']\\n')\n",
    "    f.write('Actual label: neg [' + str(cm[1][0]) + ' ' + str(cm[1][1]) + ']\\n\\n')\n",
    "    \n",
    "#Function to return chosen metrics\n",
    "def return_metrics():\n",
    "        recall = str(recall_score(target_test, pred, average = 'weighted'))\n",
    "        precision = str(precision_score(target_test, pred, average = 'weighted'))\n",
    "        f1_measure = str(f1_score(target_test, pred, average = 'weighted'))\n",
    "        accuracy = str(accuracy_score(target_test, pred, normalize = True))\n",
    "        return recall, precision, f1_measure, accuracy\n",
    "\n",
    "#Function to output predicted results to ifle\n",
    "def pred_results():\n",
    "    f.write(\"Data format:\\n\")\n",
    "    f.write(\"INDEX_OF_CLASS , PREDICTED CLASS, ACTUAL CLASS\\n\\n\")\n",
    "    for i in range(len(pred)):\n",
    "        f.write(str(int((0.80*len(all_docs))+i)) + \" , \" + pred[i] + \" , \" + target_test[i] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 3: Writing to file - Output code\n",
    "\n",
    "#Naive Bayes Output File\n",
    "mnb = MultinomialNB(alpha = 0.05)\n",
    "pred = mnb.fit(data_train, target_train).predict(data_test)\n",
    "nb_recall,nb_precision,nb_f1,nb_accuracy = return_metrics()\n",
    "\n",
    "with open(\"[naive_bayes]-[dataset].txt\", \"w+\") as f:\n",
    "    \n",
    "    #Confusion Matrix\n",
    "    cm = confusion_matrix(target_test,pred, labels =['pos','neg'])\n",
    "    mat_to_file(cm)\n",
    "    \n",
    "    #Precision, Recall, and F1-Measure\n",
    "    f.write('Recall: ' + nb_recall + '\\n')\n",
    "    f.write('Precision: ' + nb_precision + '\\n')\n",
    "    f.write('F1 Measure: ' + nb_f1 + '\\n')\n",
    "    \n",
    "    #Accuracy\n",
    "    f.write('Accuracy: ' + nb_accuracy + '\\n\\n')\n",
    "    \n",
    "    #Results\n",
    "    pred_results()\n",
    "    \n",
    "\n",
    "#DT_BASE_Output_File\n",
    "clf = DecisionTreeClassifier(criterion = 'entropy')\n",
    "pred = clf.fit(data_train,target_train).predict(data_test)\n",
    "dt_base_recall,dt_base_precision,dt_base_f1,dt_base_accuracy = return_metrics()\n",
    "\n",
    "with open(\"[dt_base]-[dataset].txt\", \"w+\") as f:\n",
    "    \n",
    "    #Confusion Matrix\n",
    "    cm = confusion_matrix(target_test,pred, labels =['pos','neg'])\n",
    "    mat_to_file(cm)\n",
    "    \n",
    "    #Precision, Recall, and F1-Measure\n",
    "    f.write('Recall: ' + dt_base_recall + '\\n')\n",
    "    f.write('Precision: ' + dt_base_precision + '\\n')\n",
    "    f.write('F1 Measure: ' + dt_base_f1 + '\\n')\n",
    "    \n",
    "    #Accuracy\n",
    "    f.write('Accuracy: ' + dt_base_accuracy + '\\n\\n')\n",
    "    \n",
    "    #Results\n",
    "    pred_results()\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "#DT_BEST_Output_File\n",
    "clf = DecisionTreeClassifier(criterion = 'entropy', class_weight = 'balanced', splitter = 'random')\n",
    "pred = clf.fit(data_train,target_train).predict(data_test)\n",
    "dt_best_recall,dt_best_precision,dt_best_f1,dt_best_accuracy = return_metrics()\n",
    "\n",
    "with open(\"[dt_best]-[dataset].txt\", \"w+\") as f:\n",
    "    \n",
    "    #Confusion Matrix\n",
    "    cm = confusion_matrix(target_test,pred, labels =['pos','neg'])\n",
    "    mat_to_file(cm)\n",
    "    \n",
    "    #Precision, Recall, and F1-Measure\n",
    "    f.write('Recall: ' + dt_best_recall + '\\n')\n",
    "    f.write('Precision: ' + dt_best_precision + '\\n')\n",
    "    f.write('F1 Measure: ' + dt_best_f1 + '\\n')\n",
    "    \n",
    "    #Accuracy\n",
    "    f.write('Accuracy: ' + dt_best_accuracy + '\\n\\n')\n",
    "    \n",
    "    #Results\n",
    "    pred_results()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 4: Error Analysis \n",
    "\n",
    "#Error Analysis - Naive Bayes\n",
    "mnb = MultinomialNB(alpha = 0.05)\n",
    "pred = mnb.fit(data_train, target_train).predict(data_test)\n",
    "\n",
    "#Creating an array that stores the index of all misclassified classes\n",
    "misclass = []\n",
    "for i in range(len(pred)):\n",
    "    if pred[i] != target_test[i]:\n",
    "        misclass.append(int((0.80*len(all_docs))+i))\n",
    "\n",
    "#for loop to double check the misclass logic - debug\n",
    "for i in range(len(misclass)):\n",
    "    if all_labels[(misclass[i])] != target_test[misclass[i]-(int(0.80*len(all_docs)))]:\n",
    "        print(\"LOGIC IS WRONG\")\n",
    "        \n",
    "#BELOW: ERROR ANALYSIS OF TWO REVIEWS        \n",
    "\n",
    "# Analysis of misclassified document: DOC 9540\n",
    "# all_docs[misclass[0]] - UNCOMMENT TO SEE REVIEW\n",
    "\n",
    "# DOC 9540 is a neg review that is classified as pos:\n",
    "# NOTE: WORDS ARE CAPITALISED IN SAMPLES FROM THE REVIEW IF I BELIEVE THAT THEY WOULD THROW THE MODEL OFF TARGET\n",
    "# \n",
    "# possible reasons:\n",
    "# (1): The reviewer makes use of a word(feature) that is commonly associated with positive reviews\n",
    "#      \"I agree with other reviewers that it feels GOOD\"\n",
    "# counter arguments:\n",
    "# (1): There are two 'negative' words(features) within the review that should serve to counteract the positive one\n",
    "#      \"nasty\", \"bad\",\n",
    "#\n",
    "# evaluation:\n",
    "# Overall, I believe that a lack of data is at issue. It could be that the model needs to be trained \n",
    "# primarily with data(reviews) that are negative but include positive words. \n",
    "# Training the model this way would help it differentiate between a model that is positive and one \n",
    "# that is negative but contains positive words.\n",
    "#\n",
    "# Having said that, training a model that way may result in a model that tends to classify positive reviews as negative.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Analysis of misclassified document: DOC 9564\n",
    "# all_docs[misclass[8]] - UNCOMMENT TO SEE REVIEW\n",
    "\n",
    "# DOC 9564 is a neg review that is classified as pos:\n",
    "# \n",
    "# possible reasons:\n",
    "# (1): The review is significantly shorter than most other reviews in the data sample.\n",
    "#     - There is less data (features) for which the model can use to predict\n",
    "# (2): The review contains no feature that is explicitly 'negative'\n",
    "#.    - The fact that the review is negative can only be understood  when taking the words in \n",
    "#       context with each other. For example:\n",
    "#       \"the price is too high\"\n",
    "#       Individually: 'the', 'price','is','too','high'\n",
    "#.      When seperated, one can see that the features(words) could easily be used in a positive review\n",
    "# \n",
    "# counter arguments:\n",
    "# (1): No real counter-argument\n",
    "# (2): The model arguably does not need to account for context. Theoretically, (with sufficient data), the model\n",
    "#      should be able to use the individual conditional probabilities of each feature to arrive at an accurate answer.\n",
    "#\n",
    "# evalutation:\n",
    "# Ultimately, I believe that the mix between (1) and (2) (the fact that it's short and has no explicit feature)\n",
    "# resulted in the misclassification of this document. There was simply not enough data in the review.\n",
    "# Both in the number of features that it contained and that the entropy of each of the included features\n",
    "# is, presumably, relatively high"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
